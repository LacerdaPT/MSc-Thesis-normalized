\section{Introduction}
\label{sec:introduction}

Between the neuron and the extracellular medium there is a voltage difference called the membrane potential. When at rest, the membrane potential is negative, around -70mV. Changes in the extracellular environment, for example synaptic activity coming from neurons upstream, can cause the membrane potential to vary. In the membrane there are also voltage-gated ion channels whose molecular structure reacts to the value of the membrane potential. When the membrane potential exceeds a certain threshold the ion channels open, allowing ions (such as Na+ and K+) to flow in and out of the neuron. This causes an abrupt change in the membrane potential called an action potential (AP). The AP is a fast, transient, and stereotypical fluctuation in the membrane potential of the nervous cell, commonly referred to as a spike. The AP propagates along the neuron following a consistent trajectory from the soma (the neuron's body) through the axon on to the synapse. 
Consequently, as ions flow during the propagation of the AP they cause a disturbance in the charge distribution of the extracellular medium, producing the extracellular action potential (EAP). The EAP is also observed to propagate outwards in the extracellular medium. \cite{kandel}

While intracellular action potentials (IAP) are very stereotyped, the EAP waveforms show a much larger variability. Not only morphological aspects of the neuron influence the characteristics of the EAP, but as the AP is propagated intracellularly there is a continuous generation of EAPs down the axon and, in some neurons, excitable dendritic structures. This leads to a complex propagation of the EAP through the extracellular medium. \cite{gold2007biophysics} \cite{pettersen2008amplitude}
 
Despite this complexity, extracellular electrophysiological recordings are still the most widely used technique to study the dynamics of neural activity. During extracellular recordings, the voltage fluctuations that surround the electrodes are measured, with the goal of detecting EAPs generated relatively close to the electrode site. In order to detect such EAPs, the signal is acquired as a time series and then, usually offline, the data is processed and spike detection is performed, where the researcher tries to find the timepoints at which an AP took place. The detected spike waveforms are then assigned to individual neurons, through a process called spike sorting.

At first, using single sharp electrodes, researchers were able to detect and sort reliably the activity of one or two neurons in the vicinity of each electrode. Using a tetrode configuration (four electrodes fairly close to each other), it is now possible to isolate up to 20 neurons (\cite{mcnaughton1983stereotrode}, \cite{gray1995tetrodes}, \cite{wilson1993dynamics}, \cite{recce1989tetrode}) in the vicinity of each probe. This increase is understandable. Due to the complexity of the propagation of the EAPs different neurons have not only different firing times but also a different set of waveforms acquired by the various electrodes. These spatiotemporal profiles (sometimes referred to as the "neuron's footprint"), dependent on the position and orientation of the probe in relation to the morphology of the firing neuron. By having a larger number of active sites in different positions of the extracellular medium, consistent differences across recorded EAPs in each site can be used to further sort the detected spikes. 

This led neuroscientists to seek out probes with more and more electrodes. Advances in microfabrication made it possible to produce probes with hundreds of electrodes densely positioned across large distances ($\sim 500 \mu m$) (http://www.neuroseeker.eu/). Employing modern methods for integrated circuit design and fabrication, probes with thousands or even millions of discrete sites are now being developed. \cite{dombovari2014vivo}, \cite{ruther2015new}, \cite{shobe2015brain}

For tetrode data, it is possible to achieve sorting error rates of 5\% or lower (\cite{harris2000accuracy}). However, the algorithms that performed fairly well on data from tetrodes do not work on the these new-generation probes. This happens due to the high dimensionality of the data: "the curse of dimensionality" greatly affects the performance of the automated part of the algorithm, and makes the manual inspection much harder.

While many different methods for spike sorting have been proposed, no method has proved robust enough to be widely adopted by the experimental community. Furthermore, since these new generation probes are larger, they are prone to sensing spatially overlapping spikes as well as temporally overlapping spikes, which doesn't happen very often with tetrodes. When EAPs from different neurons are present on the same electrode they interfere with each other constructively and destructively. This resulting waveform, if detected, will be marked as a single event and will make the sorting much harder. When two EAPs occur at the same time but sensed in different parts of the probe, most algorithms will only detect one event since they don't consider different spatial regions on the probe. The right estimation of the moment when the EAP is recorded is crucial for the success of the sorting phase. 

In Rossant et al. \cite{Rossant2016}, a method was developed that uses the information about the relative position of electrodes in a multi-electrode array in order to take advantage of the “neuron footprints”. This method comprises a spike detection algorithm (SpikeDetekt) and a spike sorting algorithm (KlustaKwik). To study the performance of these algorithms it is necessary to have a ground-truth data, but at the time of the writing of Rossant et al. such a dataset didn't exist for dense extracellular probes and for that reason they used a simulated dataset by superimposing data from recordings where one neuron was identified. With this hybrid dataset, the authors report to have achieved errors rates as low as 5\%.

In Neto et al., they performed in-vivo paired recordings with a juxtacellular pipette and new generation dense silicon probes with both 32 and 128 electrodes. With this dataset it is possible to have precise determination of when a single identified neuron was active. With this information it is possible to compute triggered averages allowing for the study of the propagation of the EAP. This allows the researcher the rare opportunity to directly compare the extracellular probe recordings with ground-truth data from one of the neurons in the recorded volume. Also, with this dataset it is possible to evaluate the performance and limitations of spike detection and spike sorting algorithms.

On the other hand, these paired recordings can also be seen as labelled datasets where each portion of the extracellular recording is assigned a classification regarding whether or not it contains an EAP from the neuron recorded by the juxtacellular probe. This provides a suitable dataset for the use of machine learning techniques, in particular, supervised learning.

Machine Learning is a sub-field of computer science that studies and develops algorithms meant to find new structure or rules to explain a given experiment or phenomenon. In machine learning, a computer receives a set of examples of inputs and it tries to determine the dependence between them. For example, given a large number of pairs of height and weight from many people, the computer tries to determine hidden relations between one parameter and the other.
 
Moreover, the relations found by the computer should be generalizable to regions of the input space where no example was provided. If this is accomplished it is said that the computer found a predictor. In other words, scientists want to be able to predict the right output of the phenomenon under study even in situations that weren't considered in the set of examples. 
In cases where each of the input examples is paired with the “correct answer” that a model should output, we have a supervised learning problem.

When applying machine learning, a model or an heuristic must be chosen a priori. This assumption conditions the success of the learning. One such model can be a linear dependence between inputs and outputs. However, in many situations, this model is too simple to yield satisfactory results. In particular in the case of classification task, the boundary in the input space that separates the  classes may not be a plane, and therefore the linear model is not a good classifier.

For this reason, Artificial Neural Networks (ANN) were invented. These are a family of models inspired by the biological neural networks of the brain. In these models, many simple computational units called artificial neurons are connected together in order to yield much more complex computations, allowing them to solve hard classification problems where the decision boundary is very complex.

In this framework, a model is defined by determining how the artificial neurons are connected. When determining the model in the ANN framework, it is necessary to choose its architecture: how many artificial neurons, how many layers, how many neurons per layer and how they are connected to each other. However, the training of ANN was very complicated until the advent of the backpropagation method for computation of gradients in 1970s.  But even after this, deep neural networks (ANNs with more than 3 layers) would suffer from the problem of the “vanishing gradients”, making the training extremely slow (\cite{hochreiter2001gradient}).

Although shallow neural networks (ANNs with at most 3 layers) can be used to learn many difficult tasks, Deep Neural Networks (DNN) were always theoretically more appealing since in each layer lies a more abstract representation of the input layer, and therefore could be more “human-like” (\cite{rumelhart1988learning}). However, only in 2006 could DNNs be properly trained due to discoveries on initialization methods (\cite{hinton2006fast}, \cite{bengio2007greedy}) and the use of GPU accelerated algorithms. (\cite{raina2009large}) Since then, deep neural networks have been used on tasks such as image and speech recognition and in some cases have achieved “superhuman” levels of accuracy.

\section{Document Outline}
In the present document, I report the attempt of applying methods from deep learning to the task of spike detection. In Chapter 2, I will present in detail the dataset from Neto et al. And how it was acquired. I will present the results of applying SpikeDetekt to the dataset and assert its accuracy. In Chapter 3, I first define and explain some of methods of machine learning and deep learning and then present the results from the implementation of such algorithms to generate a spike detection method for multi-electrode array recordings and compare it to the results from SpikeDetekt. Finally, I conclude presenting the significance of the results obtained and propose future steps to be taken.

