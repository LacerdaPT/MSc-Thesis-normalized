% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% The Introduction:
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\fancychapter{Conclusions and Future Work}
\label{cap:conclusions}

\section{Conclusions}
In this document is reported the attempt to assess the viability of pursuit of better spike detection algorithms in the context of deep learning. 

Neto et al. provided a much necessary ground-truth dataset consisting of simultaneous recordings from one juxtacellular pipette and large, dense extracellular probe. With these data I studied the performance of the state-of-the-art algorithm SpikeDetekt and pointed out some of limitations of this method and challenges these new-generation probes raise that researchers still have to resolve. To face these problems, I tried to implement feed-forward deep neural networks to detect Extracellular Action Potentials of one particular neuron on the same data. Comparing the results with the ones from SpikeDetekt it seems to lead us to the conclusion that this approach may be a better solution, since the deep learning approach was able to yield better results on datasets used. Although some of the results are promising, some aspects should reconsidered, in particular the training set. 

This work should, however, be regarded as a "proof of concept". While SpikeDetekt tries to find all spikes in a record, each Deep Neural Network was trained to detect the EAP of one specific neuron whose activity was monitored with the juxta-cellular probe, and not the spikes from any neuron. Nonetheless, in my opinion, the success achieved detecting the spikes from only one neuron justifies further effort to be put in developing algorithms under a deep learning framework.


\section{Future Work}
Indeed, much remains to be done. In the particular context of this document, the architecture, training method and hyperparameters should be further studied to achieve optimal values as universal as possible for learning with any dataset.

First, I think the deep learning setup in this document should be applied with the entire datasets to truly assess the reliability of the one-neuron detection. And next obvious step should be the use of several datasets as discussed in Sec. \ref{sec:chap3-discussion}. In any case it would be interesting to perform layer visualization techniques to understand what each layer was trained to compute. With this knowledge the progression of these algorithm becomes less blind allowing researchers to zero in on the best possible network.

Since each electrode is sensing the different "versions" of the same phenomenon there probably is redundancy in the data from the probe. Therefore it would be interesting to apply some dimensionality reduction algorithm (such as PCA) prior to the training. This would reduce the size of the network, and thus the number of parameters, without much loss of relevant information, allowing for better training. In fact it is possible that this procedure makes the signal of interest stand out by discarding noise components of the signal, in which case spikes with lower and lower amplitude could be detected.

The datasets I based this work on were recorded using 128-channel planar probe spanning over 90 $\mu m$ in one direction and 717.5 $\mu m$ on the other. Neurons in its vicinity usually only impress a small portion of the probe. Therefore a spike detection algorithm for such probe should be agnostic to where the neuron's footprint rests. In other words, it should be translation invariant. So, moving forward from this work, I think it would be useful to try applying Convolutional Neural Networks, where the adjustable parameters are actually many small sized kernels that are convolved with the output of the previous layer. Regardless of where the neuron's footprint appeared a well-trained kernel could be run through the whole probe and would eventually result in a positive identification.

Another possible use for deep neural network would be to train a noise filter. The raw filtered signal would be fed in the input layer and then supervised learning would train the DNN to provide the Juxta-Triggered Averages (JTA). If successfully trained, the resulting output would be relatively noise-free and a simple threshold-based detection algorithm could be applied. If many different recordings were utilized, perhaps the resulting DNN could be universal enough to used in any recording.
Analysing the layers of this trained network, this could also help researchers understand what the biological noise in the extracellular medium really is.

\cleardoublepage
